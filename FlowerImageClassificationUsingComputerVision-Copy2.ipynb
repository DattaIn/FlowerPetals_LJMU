{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-atCj1OTCuo"
   },
   "source": [
    "# Flower image classification using Computer Vision\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4706,
     "status": "ok",
     "timestamp": 1573965427758,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "8_KimioOTNR4",
    "outputId": "c2f8b0e1-f647-44d1-e46b-53973748d75d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "random.seed(32)\n",
    "\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#image handling libraries\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy import ndimage\n",
    "\n",
    "#skimage library imports\n",
    "from skimage import io, filters, morphology, measure\n",
    "from skimage.measure import label,  regionprops\n",
    "from skimage.filters import sobel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pickle\n",
    "\n",
    "# keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "from keras.layers.merge import add\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "#Diagnostic libraries\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderName = r'../Storage'\n",
    "imageDir = folderName + '/train_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1573967558980,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "t23ARO75CQqG",
    "outputId": "8a02a0b2-5640-4124-8934-f6bdc40b9b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Names\n",
      "1                 'pink primrose'\n",
      "2     'hard-leaved pocket orchid'\n",
      "3              'canterbury bells'\n",
      "4                     'sweet pea'\n",
      "5              'english marigold'\n",
      "..                            ...\n",
      "98              'mexican petunia'\n",
      "99                     'bromelia'\n",
      "100              'blanket flower'\n",
      "101             'trumpet creeper'\n",
      "102             'blackberry lily'\n",
      "\n",
      "[102 rows x 1 columns]\n",
      "\n",
      "Test Print: FLower Name and its unique label\n",
      "Names     'passion flower'\n",
      "Name: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#oxford102_flower_dataset_labels.txt contains a dataset where index is the unique label and column \"Names\" is the name of the flower for the image label id \n",
    "#read labels from oxford102_flower_dataset_labels.txt\n",
    "oxford102_labels = pd.read_csv('oxford102_flower_dataset_labels.txt', delimiter='\\t', header=None, names=['Names'])\n",
    "# Image labels are 1 based, changed the index of the image database label\n",
    "oxford102_labels.index = np.arange(1, len(oxford102_labels) + 1)\n",
    "print(oxford102_labels)\n",
    "print()\n",
    "print(\"Test Print: FLower Name and its unique label\")\n",
    "print(oxford102_labels.loc[77])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HS3J48e1tuw"
   },
   "source": [
    "### Assumptions\n",
    "###1. If there is no definit number petals for a flower, then the petal count may or may not be added to the oxford102lables dictionary.\n",
    "###2. The predicted petals count may or may not be displayed based on input from the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-aKolLcoFdCN"
   },
   "source": [
    "##Extract Features using model for image classification with weights trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cnrdy3KHCn4"
   },
   "outputs": [],
   "source": [
    "# config variables\n",
    "model_name    = \"resnet50\" #\"vgg16\"  #\"inceptionv3\"\n",
    "weights       = \"imagenet\"\n",
    "include_top   = False #input shape will be specified, so it is false \n",
    "features_path = \"output/flowers_102/resnet50/features.h5\"\n",
    "labels_path   = \"output/flowers_102/resnet50/labels.h5\"\n",
    "test_size     = 0.02 #80% training data and 20% test data\n",
    "results       = \"output/flowers_102/resnet50/results.txt\"\n",
    "model_path    = \"output/flowers_102/resnet50/model\"\n",
    "num_classes   = 102\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10560,
     "status": "ok",
     "timestamp": 1573356402065,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "cy3Zzce-KVdx",
    "outputId": "95c1c040-625e-4886-9f63-e5db9e033be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "if model_name == \"vgg16\":\n",
    "  base_model = VGG16(weights=weights)\n",
    "  #base_model.summary()\n",
    "  #model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "  image_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "  base_model = VGG19(weights=weights)\n",
    "  model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "  image_size = (224, 224)\n",
    "elif model_name == \"resnet50\":\n",
    "  base_model = ResNet50(weights=weights)\n",
    "  #base_model.summary()\n",
    "  # add a global spatial average pooling layer\n",
    "  x = base_model.get_layer('avg_pool').output\n",
    "  #x = GlobalAveragePooling3D()(x)\n",
    "  # let's add a fully-connected layer\n",
    "  #x = Dense(2048, activation='relu')(x)\n",
    "  # and a logistic layer -- we have 102 classes\n",
    "  #predictions = Dense(num_classes, activation='softmax')(x)\n",
    "  #model = Model(input=base_model.input, output=base_model.get_layer('fc1000').output)\n",
    "  model = Model(inputs=base_model.input, outputs=x)\n",
    "  model.summary()\n",
    "  image_size = (224, 224)\n",
    "elif model_name == \"inceptionv3\":\n",
    "  base_model = InceptionV3(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "  base_model.summary()\n",
    "  #model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "  #image_size = (299, 299)\n",
    "elif model_name == \"inceptionresnetv2\":\n",
    "  base_model = InceptionResNetV2(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "  model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "  image_size = (299, 299)\n",
    "elif model_name == \"mobilenet\":\n",
    "  base_model = MobileNet(include_top=include_top, weights=weights, input_tensor=Input(shape=(224,224,3)), input_shape=(224,224,3))\n",
    "  model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "  image_size = (224, 224)\n",
    "elif model_name == \"xception\":\n",
    "  base_model = Xception(weights=weights)\n",
    "  model = Model(input=base_model.input, output=base_model.get_layer('avg_pool').output)\n",
    "  image_size = (299, 299)\n",
    "else:\n",
    "  base_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14601,
     "status": "ok",
     "timestamp": 1573308208046,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "Q0XVTw0_p7bN",
    "outputId": "22fb51d4-96d9-41bd-a4b9-bc9f7b7f1ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and weights to disk..\n"
     ]
    }
   ],
   "source": [
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(folderName + \"/\" + model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "# save weights\n",
    "model.save_weights(folderName + \"/\" + model_path + str(test_size) + \".h5\")\n",
    "print(\"Saved model and weights to disk..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14688,
     "status": "ok",
     "timestamp": 1573357408735,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "eUyvC_rQW9_M",
    "outputId": "71495644-0f99-402e-d434-8a88b460ce6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open(folderName + \"/\" + model_path + \"0.02\" + \".json\", 'r')\n",
    "loaded_pretrained_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_pretrained_model = model_from_json(loaded_pretrained_model_json)\n",
    "# load weights into new model\n",
    "loaded_pretrained_model.load_weights(folderName + \"/\" + model_path + \"0.02\" + \".h5\")\n",
    "print(\"Loaded pretrained model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o47K1RPgFU3B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'english marigold', 'tiger lily', 'moon orchid', 'bird of paradise', 'monkshood', 'globe thistle', 'snapdragon', '\"colts foot\"', 'king protea', 'spear thistle', 'yellow iris', 'globe-flower', 'purple coneflower', 'peruvian lily', 'balloon flower', 'giant white arum lily', 'fire lily', 'pincushion flower', 'fritillary', 'red ginger', 'grape hyacinth', 'corn poppy', 'prince of wales feathers', 'stemless gentian', 'artichoke', 'sweet william', 'carnation', 'garden phlox', 'love in the mist', 'mexican aster', 'alpine sea holly', 'ruby-lipped cattleya', 'cape flower', 'great masterwort', 'siam tulip', 'lenten rose', 'barbeton daisy', 'daffodil', 'sword lily', 'poinsettia', 'bolero deep blue', 'wallflower', 'marigold', 'buttercup', 'oxeye daisy', 'common dandelion', 'petunia', 'wild pansy', 'primula', 'sunflower', 'pelargonium', 'bishop of llandaff', 'gaura', 'geranium', 'orange dahlia', 'pink-yellow dahlia?', 'cautleya spicata', 'japanese anemone', 'black-eyed susan', 'silverbush', 'californian poppy', 'osteospermum', 'spring crocus', 'bearded iris', 'windflower', 'tree poppy', 'gazania', 'azalea', 'water lily', 'rose', 'thorn apple', 'morning glory', 'passion flower', 'lotus', 'toad lily', 'anthurium', 'frangipani', 'clematis', 'hibiscus', 'columbine', 'desert-rose', 'tree mallow', 'magnolia', 'cyclamen', 'watercress', 'canna lily', 'hippeastrum', 'bee balm', 'ball moss', 'foxglove', 'bougainvillea', 'camellia', 'mallow', 'mexican petunia', 'bromelia', 'blanket flower', 'trumpet creeper', 'blackberry lily']\n"
     ]
    }
   ],
   "source": [
    "#Test Print : Training labels\n",
    "train_labels = oxford102_labels.Names.tolist()\n",
    "train_labels = [i.replace(\"'\", \"\").strip() for i in train_labels]\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3WpkcvlFEAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Encoding labels*******\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the labels\n",
    "print(\"*******Encoding labels*******\")\n",
    "le = LabelEncoder()\n",
    "le.fit([tl for tl in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nO4p8cRuGGGT"
   },
   "outputs": [],
   "source": [
    "#Load image database\n",
    "pickle_in = open(folderName + \"/\" + \"dict.image_database.pickle\",\"rb\")\n",
    "image_database = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN6YzonuCh_b"
   },
   "source": [
    "### Flower Detection Using Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnNw6gtAFewx"
   },
   "source": [
    "###Create Training Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "984N0xcJwvWv"
   },
   "source": [
    "### Trial with LSTM model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2Tk5SaQwnXq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define the captioning model\n",
    "def define_model(vocab_size, max_length):\n",
    "    \n",
    "    # feature extractor model\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    # modified on 9th November\n",
    "    fe2 = Dense(1024, activation='relu')(fe1)\n",
    "    fe3 = Dropout(0.5)(fe2)\n",
    "    fe4 = Dense(512, activation='relu')(fe3)\n",
    "    fe5 = Dropout(0.5)(fe4)\n",
    "    fe6 = Dense(256, activation='relu')(fe5)\n",
    "\n",
    "    # sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    #added another dropout layer on 9th nov\n",
    "    se3 = LSTM(256)(se2)\n",
    "\n",
    "    # decoder model\n",
    "    decoder1 = add([fe6, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    \n",
    "    print(\"[inputs1, inputs2]\", [inputs1, inputs2])\n",
    "    \n",
    "    # tie it together [image, seq] [word]\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    #In case of GPU the below method does not work.!!!\n",
    "    #plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7IEtRReSV9Y"
   },
   "source": [
    "### Create Vocabulary for Training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_vocab = pd.read_csv('flowers_with_petals_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Name</th>\n",
       "      <th>Petals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>'primula'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>'orange dahlia'</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>'cape flower'</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>'water lily'</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>'black-eyed susan'</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                 Name  Petals\n",
       "0        53            'primula'       2\n",
       "1        59      'orange dahlia'       5\n",
       "2        37        'cape flower'       4\n",
       "3        73         'water lily'       5\n",
       "4        63   'black-eyed susan'       3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of number of files in this folder and all subfolders\n",
    "def get_num_files(path):\n",
    "  if not os.path.exists(path):\n",
    "    return 0\n",
    "  return sum([len(files) for r, d, files in os.walk(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9q2C-AfP0Cm9"
   },
   "outputs": [],
   "source": [
    "word_vocab = {}\n",
    "for img_num in train_img_nums:\n",
    "    if img_num in image_database:\n",
    "        img_data = image_database[img_num]\n",
    "        word_vocab[img_num] = 'startseq ' + ' '.join(str(img_num) + ' ' + img_data[0]) + ' endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1573467560184,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "rkH6DUAHCkj1",
    "outputId": "fa1b2649-74da-44f6-cf96-66a30c73176e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startseq 0 1 0 5 3   w a l l f l o w e r endseq\n"
     ]
    }
   ],
   "source": [
    "test =list()\n",
    "for key, val in word_vocab.items():\n",
    "  print(val)\n",
    "  test.append(val)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5_i12tjROpJ"
   },
   "outputs": [],
   "source": [
    "# convert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(vocab):\n",
    "    all_desc = list()\n",
    "    for key, val in vocab.items():\n",
    "      all_desc.append(val)\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLOSoDuLRA3c"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(vocab):\n",
    "    lines = to_lines(vocab)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1573467580674,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "k7TxsEf_vM2A",
    "outputId": "6d33728b-fb57-4923-b412-fd0d80cbe827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x00000279A1A35208>\n",
      "Vocabulary Size:  39\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer(word_vocab)\n",
    "print(tokenizer)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGpKoIOkzPiP"
   },
   "outputs": [],
   "source": [
    "def max_lengthTEMP(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1573312313876,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "OBX6QW9JFlIy",
    "outputId": "b6f56643-7c3d-4616-be95-a57c4f036ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "seq = [[150, 5, 2]]\n",
    "print(seq[0][1])# seq[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1573467590290,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "5-aFg3F7HhLh",
    "outputId": "4f7b90f2-1172-4f8e-cda9-b45dc8347328"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5317"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1573312322177,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "IBwiqsr2ZdPt",
    "outputId": "89c46810-8b20-44cc-9775-e7f9093ae373"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yz5LPbkR1qSf"
   },
   "outputs": [],
   "source": [
    "def max_length_sentence_in_word_vocab(word_vocab):\n",
    "  return max(len(i.split()) for i in word_vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1573467602023,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "bx5U5oG-30VL",
    "outputId": "a482937f-ddcc-411c-ad7b-e848f3e905a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_sentence_in_word_vocab(word_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43utX2vzSrHw"
   },
   "source": [
    "###Create Vocabulary for Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSea_GxxSohQ"
   },
   "outputs": [],
   "source": [
    "test_word_vocab = {}\n",
    "for img_num in test_img_nums:\n",
    "    if img_num in image_database:\n",
    "        img_data = image_database[img_num]\n",
    "        test_word_vocab[img_num] = 'startseq ' + ' '.join(str(img_num) + ' ' + img_data[0]) + ' endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1573467611786,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "bAVgtX_zinfe",
    "outputId": "e42f635a-b5cb-44ab-b08a-b5732849d39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x00000279A1A35320>\n",
      "Vocabulary Size:  39\n"
     ]
    }
   ],
   "source": [
    "test_tokenizer = create_tokenizer(test_word_vocab)\n",
    "print(test_tokenizer)\n",
    "test_vocab_size = len(test_tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: ', test_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqeLf8nLUOgU"
   },
   "source": [
    "###Extract test image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZD6CAHgOUtUT"
   },
   "outputs": [],
   "source": [
    "test_img_features = {}\n",
    "test_labels_features = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 956703,
     "status": "ok",
     "timestamp": 1573358479947,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "F36kpDQCUKit",
    "outputId": "b7df9f05-447f-4793-b88c-ed1e4e688497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1580/1580 [00:39<00:00, 39.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_id in tqdm(test_img_nums):\n",
    "  \n",
    "  if img_id in image_database:  \n",
    "    \n",
    "    img_data = image_database[img_id]\n",
    "    img = load_img(img_data[1], target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n",
    "    x = preprocess_input(x)\n",
    "    feature = loaded_pretrained_model.predict(x)\n",
    "    test_img_features[img_id] = feature\n",
    "    test_labels_features.add(img_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usy76RxJhRiY"
   },
   "source": [
    "####Save test image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iihf_qbghL7r"
   },
   "outputs": [],
   "source": [
    "pickle_out = open(folderName + \"/\" + \"dict.test_image_features.pickle\",\"wb\")\n",
    "pickle.dump(test_img_features, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoy3yMpX3zXV"
   },
   "outputs": [],
   "source": [
    "#the below function loop forever with a while loop and within this, \n",
    "#loop over each image in the image directory. \n",
    "#For each image filename, we can load the image and \n",
    "#create all of the input-output sequence pairs from the images description.\n",
    "\n",
    "#data generator, intended to be used in a call to model.fit_generator()\n",
    "def data_generator(vocab, photos, tokenizer, max_length):\n",
    "    while 1:\n",
    "        for key, description_list in vocab.items():\n",
    "            #retrieve photo features\n",
    "            img = photos[key][0]            \n",
    "            input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, img)\n",
    "            \n",
    "            X = [ input_image, input_sequence]\n",
    "            yield [X, output_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ531PZL5iQG"
   },
   "outputs": [],
   "source": [
    "#we are calling the create_sequence() function to create \n",
    "#a batch worth of data for a single photo rather than an entire dataset. \n",
    "#This means that we must update the create_sequences() function \n",
    "#to delete the iterate over all descriptions for-loop.            \n",
    "#Updated create sequence function for data_generator\n",
    "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    # walk through each description for the image\n",
    "    for desc in desc_list.split(' '):\n",
    "      # encode the sequence\n",
    "      seq = tokenizer.texts_to_sequences([desc_list])[0]\n",
    "      # split one sequence into multiple X,y pairs\n",
    "      for i in range(1, len(seq)):\n",
    "          # split into input and output pair\n",
    "          in_seq, out_seq = seq[:i], seq[i]\n",
    "          # pad input sequence\n",
    "          in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "          # encode output sequence\n",
    "          out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "          # store\n",
    "          X1.append(photo)\n",
    "          X2.append(in_seq)\n",
    "          y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UlkXulBjcxO"
   },
   "outputs": [],
   "source": [
    "max_length = max_lengthTEMP(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bRTVrpBjevB"
   },
   "outputs": [],
   "source": [
    "test_max_length = max_lengthTEMP(test_word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1573312396993,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "938V8tsxAPsD",
    "outputId": "3bec59ba-cf69-465f-c500-1317e8b62345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length:  30\n",
      "[inputs1, inputs2] [<tf.Tensor 'input_12:0' shape=(None, 2048) dtype=float32>, <tf.Tensor 'input_13:0' shape=(None, 30) dtype=float32>]\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 2048)         0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1024)         2098176     dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1024)         0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 512)          524800      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 30, 256)      9984        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 512)          0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 30, 256)      0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 256)          131328      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 256)          525312      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 256)          0           dense_28[0][0]                   \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          65792       add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 39)           10023       dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,365,415\n",
      "Trainable params: 3,365,415\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "epochs = 32\n",
    "steps = len(word_vocab)\n",
    "max_length = max_lengthTEMP(word_vocab)\n",
    "print(\"max_length: \", max_length)\n",
    "\n",
    "model_LSTM = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XucoKRhU1Aih"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Data Generator \n",
      "Epoch 1/64\n",
      "5317/5317 [==============================] - 605s 114ms/step - loss: 0.5233\n",
      "Epoch 2/64\n",
      "5317/5317 [==============================] - 602s 113ms/step - loss: 0.5206\n",
      "Epoch 3/64\n",
      "5317/5317 [==============================] - 607s 114ms/step - loss: 0.5182\n",
      "Epoch 4/64\n",
      "5317/5317 [==============================] - 604s 114ms/step - loss: 0.5190\n",
      "Epoch 5/64\n",
      "5317/5317 [==============================] - 606s 114ms/step - loss: 0.5174\n",
      "Epoch 6/64\n",
      "5317/5317 [==============================] - 602s 113ms/step - loss: 0.5135\n",
      "Epoch 7/64\n",
      "5317/5317 [==============================] - 601s 113ms/step - loss: 0.5140\n",
      "Epoch 8/64\n",
      "5317/5317 [==============================] - 601s 113ms/step - loss: 0.5128\n",
      "Epoch 9/64\n",
      "5317/5317 [==============================] - 607s 114ms/step - loss: 0.5100\n",
      "Epoch 10/64\n",
      "5317/5317 [==============================] - 609s 115ms/step - loss: 0.5067\n",
      "Epoch 11/64\n",
      "5317/5317 [==============================] - 603s 113ms/step - loss: 0.5049\n",
      "Epoch 12/64\n",
      "5317/5317 [==============================] - 605s 114ms/step - loss: 0.5038\n",
      "Epoch 13/64\n",
      "5317/5317 [==============================] - 601s 113ms/step - loss: 0.5012\n",
      "Epoch 14/64\n",
      "5317/5317 [==============================] - 604s 114ms/step - loss: 0.4997\n",
      "Epoch 15/64\n",
      "5317/5317 [==============================] - 600s 113ms/step - loss: 0.4978\n",
      "Epoch 16/64\n",
      "5317/5317 [==============================] - 608s 114ms/step - loss: 0.4963\n",
      "Epoch 17/64\n",
      "5317/5317 [==============================] - 606s 114ms/step - loss: 0.4936\n",
      "Epoch 18/64\n",
      "2307/5317 [============>.................] - ETA: 5:43 - loss: 0.4851"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print(\"Initialize Data Generator \")\n",
    "    generator = data_generator(word_vocab, img_features_loaded, tokenizer, max_length)\n",
    "    model_LSTM.fit_generator(generator, epochs=epochs, steps_per_epoch=steps, verbose=1)\n",
    "    model_LSTM.save(folderName + 'model_LSTM_' + str(i) + '.h5')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5783,
     "status": "ok",
     "timestamp": 1573467089282,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "1HHN12mKVy2N",
    "outputId": "f74c58f5-d1d3-4051-ece4-47836ddd5641"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\datta_tensorflow_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#load the latest model\n",
    "model_path = folderName + 'model_LSTM_' + str(31) + '.h5'\n",
    "loaded_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSQmOk82Qx22"
   },
   "outputs": [],
   "source": [
    "pickle_in = open(folderName + \"/\" + \"dict.testing_img_data.pickle\",\"rb\")\n",
    "testing_img_data = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Do3Pm7ULIDzP"
   },
   "outputs": [],
   "source": [
    "pickle_in = open(folderName + \"/\" + \"dict.test_image_features.pickle\",\"rb\")\n",
    "test_img_features = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahC3XK67j3B3"
   },
   "outputs": [],
   "source": [
    "# generate a description for an image\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    # seed the generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the whole length of the sequence\n",
    "    for i in range(max_length):\n",
    "        # integer encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad input\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        # convert probability to integer\n",
    "        yhat = argmax(yhat)\n",
    "        # map integer to word\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        # stop if we cannot map the word\n",
    "        if word is None:\n",
    "            break\n",
    "        # append as input for generating the next word\n",
    "        in_text += ' ' + word\n",
    "        # stop if we predict the end of the sequence\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pE5925Ek4By"
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-a-UwoeQfdjW"
   },
   "outputs": [],
   "source": [
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
    "\tactual, predicted = list(), list()\n",
    "\t# step over the whole set\n",
    "\tfor key, desc in descriptions.items():\n",
    "\t\t# generate description\n",
    "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
    "\t\t# store actual and predicted\n",
    "\t\treferences = [d.split() for d in desc]\n",
    "\t\tactual.append(references)\n",
    "\t\tpredicted.append(yhat.split())\n",
    "\tprint('Actual:    %s' % desc)\n",
    "\tprint('Predicted: %s' % yhat)\n",
    "\t# calculate BLEU score\n",
    "\tbleu = corpus_bleu(actual, predicted)\n",
    "\treturn bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2buiwbZh63R"
   },
   "outputs": [],
   "source": [
    "train_results = []\n",
    "test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326929,
     "status": "ok",
     "timestamp": 1573478769864,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "lblr0nNJReUp",
    "outputId": "718e28cb-eb8a-44a9-e450-46e617f95e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:    startseq 0 4 1 2 5   a r t i c h o k e endseq\n",
      "Predicted: startseq 0 3 0 3 1 b e e b a l m endseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\datta_tensorflow_gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\programdata\\anaconda3\\envs\\datta_tensorflow_gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\programdata\\anaconda3\\envs\\datta_tensorflow_gpu\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days: 0, Hours: 0, Minutes: 14, Seconds: 57\n",
      "Actual:    startseq 0 1 4 5 0   p e t u n i a endseq\n",
      "Predicted: startseq 0 5 4 6 2 a z a l e a endseq\n",
      "Days: 0, Hours: 0, Minutes: 3, Seconds: 39\n"
     ]
    }
   ],
   "source": [
    "start_train_eval = time.time()\n",
    "train_score = evaluate_model(loaded_model, word_vocab, img_features_loaded, tokenizer, max_length)\n",
    "end_train_eval = time.time()\n",
    "stopwatch(end_train_eval-start_train_eval)\n",
    "start_test_eval = time.time()\n",
    "test_score = evaluate_model(loaded_model, test_word_vocab, test_img_features, test_tokenizer, test_max_length)\n",
    "end_test_eval = time.time()\n",
    "stopwatch(end_test_eval-start_test_eval)\n",
    "# store\n",
    "train_results.append(train_score)\n",
    "test_results.append(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1573478922809,
     "user": {
      "displayName": "Indranil Datta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA6cIm_H2hBWOCi63zBJ1ZOUWdCEmhuiDizxgUq=s64",
      "userId": "01841605799373654513"
     },
     "user_tz": -330
    },
    "id": "Q8v32vl_pZ0Y",
    "outputId": "0308a090-168e-46e4-a3e0-9129caa72690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score: 1.4554353610080036e-231 And test score: 1.449176985142455e-231\n"
     ]
    }
   ],
   "source": [
    "print(\"The train score: {0} And test score: {1}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FlowerImageClassificationUsingComputerVision.ipynb",
   "provenance": [
    {
     "file_id": "1uiwE8vZnK8URzBnK1lwK65aHrwfDx5GN",
     "timestamp": 1573915622038
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
